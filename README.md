# アマデウスシステムアーキテクチャ（コアプロット）

本ドキュメントは、アマデウスプロトタイプのシステム要件とアーキテクチャ設計の概要を示す。目標は、1か月以内に、牧瀬紅莉栖の人格を備えたリアルタイム音声対話型AIアシスタントを構築することである。

## 1. システム構成要素（アマデウスの構造）

本システムは、独立したモジュール群として設計されており、個別のテストや将来のアップグレード（例：ローカルモデルを別のAPIに置き換えること）を可能にします。

### 1.1 ブレイン（LLMコアとメモリ）
- **役割:** 入力テキストを処理し、文脈を維持し、知識を呼び出し、人格に基づいた応答を生成します。
- **エンジン:** Gemini 2.5 Flash API（`google-genai` SDK経由）。
- **主な機能:**
    - 低遅延応答生成のためのストリーミング出力（`send_message_stream`）。
    - 牧瀬紅莉栖の人格を強制するシステム指示。
    - 複数ターン文脈のためのChatSessionメモリ。
    - (将来) 特定知識検索のためのChromaDB経由RAG統合。
- **ファイル:** `AmadeusSystem/amadeus_core.py`

### 1.2 耳（音声認識／STT）
- **役割：** ユーザーのマイクから音声を聴き取り、発話を検知してテキストに変換します。
- **エンジン：** Faster Whisper（ローカル推論）。
- **主な機能：**
    - (将来) 音声活動検出（VAD）により、ユーザーの話し始めと話し終わりを認識。
    - ブレインの処理開始までの遅延を最小限に抑えるため、速度最適化済み。
- **ファイル:** `AmadeusSystem/amadeus_ear.py` 

### 1.3 口（テキスト読み上げ／TTS）future
- **役割：** ブレインが生成したテキストを、クリスの声を模した音声ファイル（WAV）に変換し、再生する。
- **エンジン：** GPT-SoVITS または RVC（ローカル推論 API）。
- **主な機能:**
    - ブレインのストリーミング出力からテキストチャンクを受信。
    - 音声を生成・再生する処理を非同期化し、ほぼリアルタイムの会話を実現。
- **ファイル:** `AmadeusSystem/amadeus_tts.py` (計画中)

## 2. データフロー（会話ループ）

1. **リスニング:** `amadeus_ear.py` はマイクを常時監視します。ユーザーが話し終えると、テキスト文字列（例: "おはよう"）を返します。
2. **思考:** メインループはこの文字列を`amadeus_core.py`に渡します。Brainはストリーミング方式でGemini APIをクエリします。
3. **発話:** Geminiがテキストチャンク（例: "おはよう、助手。"）を生成すると、`amadeus_core.py`はこれらのチャンクを即座に`amadeus_tts.py`に渡します。
4. **再生:** `amadeus_tts.py`はそのチャンクの音声を生成し、Brainが残りの文を生成している間に再生します。
## 3. 開発フェーズ（1ヶ月計画）

### フェーズ4.5: コアループ
- Gemini APIをラップする堅牢なPythonクラスとして`amadeus_core.py`を固める。
- ターミナルベースのテキスト会話がストリーミングと完全に連携することを保証する。


### フェーズ5.1: 感覚統合（耳）
- Faster Whisperを使用して`amadeus_ear.py`を実装する。
- 耳 → 脳の接続（端末に話しかけると、Amadeusがテキストで応答）。

### フェーズ5.2: 発声統合（口）（現在の目標）
- ローカルのGPT-SoVITS/RVCサーバーに接続する`amadeus_tts.py`を実装。
- 脳 → 口の接続（端末に入力すると、Amadeusが音声で応答）。

### フェーズ6: 完全なループの構築
- 耳 → 脳 → 口の接続を確立する。
- レイテンシの調整、中断処理、および全体を統括する`main.py`コントローラーの最適化を行う。

